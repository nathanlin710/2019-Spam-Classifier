{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22492\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os, re, csv\n",
    "\n",
    "# there are total of 65 xlsx files in data folder\n",
    "# collect 'T/F' and 'Tweet Text' data from both xxx.tweets and xxx.tweets.TRUE sheets from each file\n",
    "# write the final collected data into onebig.csv file\n",
    "\n",
    "dfs = []\n",
    "for fname in os.listdir(\"/Users/nathanlin/2019spamClassify/data\"):\n",
    "    if re.search(r'\\.xlsx$', fname):\n",
    "        #print(fname)\n",
    "        file_name = 'data/' + fname\n",
    "        xls = pd.ExcelFile(file_name)\n",
    "        for sheetname in [xls.sheet_names[0], xls.sheet_names[1]]:\n",
    "            df = pd.read_excel(file_name, sheet_name=sheetname)\n",
    "            dfs.append(df)\n",
    "\n",
    "# this step is to generate onebig csv file from 2 columns: 'T/F' and 'Tweet Text'\n",
    "csv_arr = []\n",
    "for df in dfs:\n",
    "    # get \"T/F\" location\n",
    "    answer_index = (list(df)).index(\"T/F\")\n",
    "    # get \"Tweet Text\" location\n",
    "    text_index = (list(df)).index(\"Tweet Text\")\n",
    "    for index, row in df.iterrows():\n",
    "        # skip 1st row as it is header\n",
    "        if index == 0:\n",
    "            continue\n",
    "\n",
    "        answer = row[answer_index]\n",
    "        text = row[text_index]\n",
    "        # if 'T/F' value is 0, convert to 'spam'\n",
    "        # if 'T/F' value is 1, convert to 'ham'\n",
    "        if answer == 0:\n",
    "            answer = 'spam'\n",
    "        else:\n",
    "            answer = 'ham'\n",
    "        csv_arr.append([answer, text])\n",
    "print(len(csv_arr))\n",
    "\n",
    "# write csv\n",
    "with open('onebig.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "            quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow(['v1', 'v2'])\n",
    "\n",
    "    for row in csv_arr:\n",
    "        spamwriter.writerow(row)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data:\n",
      "ham     10243\n",
      "spam     7757\n",
      "Name: v1, dtype: int64\n",
      "test data:\n",
      "spam    2627\n",
      "ham     1865\n",
      "Name: v1, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/myenv3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.832146037399822\n",
      "4492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.svm import *\n",
    "import pandas\n",
    "import csv\n",
    "\n",
    "data = pandas.read_csv('onebig.csv', sep=',', header=0, encoding='latin-1')\n",
    "#print(data.columns.tolist())\n",
    "\n",
    "# use ~4/5 of data for training(18000)\n",
    "train_data = data[:18000] \n",
    "test_data = data[18000:] \n",
    "print('train data:')\n",
    "print((train_data.v1).value_counts())\n",
    "print('test data:')\n",
    "print(((test_data.v1).value_counts()))\n",
    "#classifier = OneVsRestClassifier(SVC(kernel='linear'))\n",
    "classifier = OneVsRestClassifier(LogisticRegression())\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# train\n",
    "vectorize_text = vectorizer.fit_transform(train_data.v2.values.astype('U'))\n",
    "classifier.fit(vectorize_text, train_data.v1)\n",
    "\n",
    "# score\n",
    "vectorize_text = vectorizer.transform(test_data.v2.values.astype('U'))\n",
    "score = classifier.score(vectorize_text, test_data.v1)\n",
    "print('score: {}'.format(score))\n",
    "\n",
    "\n",
    "csv_arr = []\n",
    "print(len(test_data))\n",
    "for index, row in test_data.iterrows():\n",
    "    answer = row[0]\n",
    "    text = row[1]\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        print(text)\n",
    "        print(type(text))\n",
    "        print(index)\n",
    "        print(row)\n",
    "        continue\n",
    "\n",
    "    vectorize_text = vectorizer.transform([text])\n",
    "    predict = classifier.predict(vectorize_text)[0]\n",
    "    if predict == answer:\n",
    "        result = 'right'\n",
    "    else:\n",
    "        result = 'wrong'\n",
    "    csv_arr.append([len(csv_arr), text, answer, predict, result])\n",
    "\n",
    "\n",
    "# write csv\n",
    "with open('test_score.csv', 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=';',\n",
    "            quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    spamwriter.writerow(['#', 'text', 'answer', 'predict', result])\n",
    "\n",
    "    for row in csv_arr:\n",
    "        spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    I added a video to a @YouTube playlist https:/...\n",
      "1    I liked a @YouTube video https://t.co/kFBopyvZ...\n",
      "2    Antifa Plan Civil War To Overthrow the Governm...\n",
      "3    Antifa Plan Civil War To Overthrow the Governm...\n",
      "4    Exclusive: Judi Dench, who had a Harvey Weinst...\n",
      "Name: v2, dtype: object\n",
      "0    i added a video to a youtube playlist httpaddr...\n",
      "1    i liked a youtube video httpaddr antifa plan c...\n",
      "2    antifa plan civil war to overthrow the governm...\n",
      "3    antifa plan civil war to overthrow the governm...\n",
      "4    exclusive judi dench who had a harvey weinstei...\n",
      "Name: v2, dtype: object\n",
      "(22492, 63610)\n",
      "0.9511737089201877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/myenv3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>ham</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">actual</th>\n",
       "      <th>spam</th>\n",
       "      <td>2265</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>51</td>\n",
       "      <td>2026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted      \n",
       "                 spam   ham\n",
       "actual spam      2265   157\n",
       "       ham         51  2026"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics, svm\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, learning_curve, StratifiedShuffleSplit, GridSearchCV,\n",
    "    cross_val_score)\n",
    "import pandas\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def preprocess_text(messy_string):\n",
    "    if not isinstance(messy_string, str):\n",
    "        return ' '\n",
    "    cleaned = re.sub(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b', 'emailaddr', messy_string)\n",
    "    cleaned = re.sub(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', 'httpaddr',\n",
    "                     cleaned)\n",
    "    cleaned = re.sub(r'Â£|\\$', 'moneysymb', cleaned)\n",
    "    cleaned = re.sub(\n",
    "        r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b',\n",
    "        'phonenumbr', cleaned)\n",
    "    cleaned = re.sub(r'\\d+(\\.\\d+)?', 'numbr', cleaned)\n",
    "    cleaned = re.sub(r'[^\\w\\d\\s]', ' ', cleaned) # Remove punctuation\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned) # Replace whitespace between terms with a single space\n",
    "    cleaned = re.sub(r'^\\s+|\\s+?$', '', cleaned.lower()) # Remove leading and trailing whitespace\n",
    "    return cleaned\n",
    "\n",
    "data = pandas.read_csv('onebig.csv', sep=',', header=0)\n",
    "#print(data.columns.tolist())\n",
    "\n",
    "# Encode the class labels as numbers\n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(data.v1)\n",
    "\n",
    "# Store the Tweet text data\n",
    "raw_text = data.v2\n",
    "print(raw_text.head())\n",
    "processed = raw_text.apply(preprocess_text)\n",
    "print(processed.head())\n",
    "\n",
    "\n",
    "# Construct a design matrix using an n-gram model and a tf-idf statistics\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_ngrams = vectorizer.fit_transform(processed)\n",
    "\n",
    "print(X_ngrams.shape)\n",
    "\n",
    "\n",
    "# Prepare the training and test sets using an 80/20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_ngrams,\n",
    "    y_enc,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_enc\n",
    ")\n",
    "\n",
    "# Train SVM with a linear kernel on the training set\n",
    "clf = svm.LinearSVC(loss='hinge')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute the F1 score\n",
    "print(metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Display a confusion matrix\n",
    "pandas.DataFrame(\n",
    "    metrics.confusion_matrix(y_test, y_pred),\n",
    "    index=[['actual', 'actual'], ['spam', 'ham']],\n",
    "    columns=[['predicted', 'predicted'], ['spam', 'ham']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
